name: 'Test LLM outputs'
description: 'Automatically run a before/after comparison of edited prompts and posts the result to your Pull Request.'
runs:
  using: 'node16'
  main: 'dist/index.js'
inputs:
  github-token:
    description: 'Github Token, used to add comments to the PR'
    required: true
  prompts:
    description: 'List of prompt files to watch'
    required: true
  config:
    description: 'Path to a promptfoo config file'
    required: true
  cache-path:
    description: 'Path to cache directory'
    required: false
  openai-api-key:
    description: 'OpenAI API Key'
    required: false
  azure-api-key:
    description: 'Azure API key'
    required: false
  anthropic-api-key:
    description: 'Anthropic API key'
    required: false
  huggingface-api-key:
    description: 'Huggingface API key'
    required: false
  aws-access-key-id:
    description: 'AWS Access Key ID'
    required: false
  aws-secret-access-key:
    description: 'AWS Secret Access Key'
    required: false
  replicate-api-key:
    description: 'Replicate API key'
    required: false
  palm-api-key:
    description: 'Palm API key'
    required: false
  vertex-api-key:
    description: 'Google vertex API key'
    required: false
  promptfoo-version:
    description: 'Version of promptfoo to use'
    required: false
    default: 'latest'
  no-share:
    description: 'Do not share the promptfoo result'
    required: false
    default: 'false'
  use-config-prompts:
    description: 'Use prompts from config file'
    required: false
    default: 'false'
branding:
  icon: 'box'
  color: 'yellow'
